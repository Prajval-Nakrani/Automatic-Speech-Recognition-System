{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "17D070014_CA3_Code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLdTUPIDluHK"
      },
      "source": [
        "Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saGb8mEnE1FF"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!unrar x \"/content/drive/MyDrive/Commands_Dataset.rar\" \"/content/Dataset/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9woMc52lxtv"
      },
      "source": [
        "Importing Necessary Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px7ORxOKe7RE"
      },
      "source": [
        "!pip install git+https://github.com/librosa/librosa\n",
        "\n",
        "import librosa\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import glob\n",
        "import soundfile as sf\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "from librosa.feature import rms, mfcc, delta\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from scipy.cluster.vq import kmeans, whiten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8baPEbuml1fR"
      },
      "source": [
        "Definition of Functions for performing\n",
        "1.   End Pointing\n",
        "2.   Feature Extraction\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H33S7wANfR3M"
      },
      "source": [
        "def endPointing(x, Fs, thresh, frame_length, hop_length):\n",
        "\n",
        "  STenergy = rms(y=x, frame_length=frame_length, hop_length=hop_length)[0]\n",
        "  STenergy = STenergy/np.max(STenergy)\n",
        "  STenergy = STenergy**2\n",
        "\n",
        "  # thresh = 0.01\n",
        "  audio = []\n",
        "  start = 0\n",
        "  end = 0\n",
        "  for i in range(STenergy.size):\n",
        "    if(STenergy[i] > thresh):\n",
        "      start = i\n",
        "      break\n",
        "\n",
        "  for i in np.flip(range(STenergy.size)):\n",
        "    if(STenergy[i] > thresh):\n",
        "      end = i\n",
        "      break\n",
        "\n",
        "  start = max(0, start*hop_length - int(frame_length/2))\n",
        "  end = min(x.size, end*hop_length + int(frame_length/2))\n",
        "\n",
        "  audio = x[start:end]\n",
        "\n",
        "  return audio\n",
        "\n",
        "def featureExtraction(x, Fs, frame_length, hop_length):\n",
        "  MFCC = mfcc(y=audio, sr=Fs, hop_length=hop_length, win_length=frame_length)\n",
        "  MFCC = MFCC[:13,:]\n",
        "  MFCC_delta = delta(MFCC, mode='mirror')  \n",
        "  MFCC_delta2 = delta(MFCC, order=2, mode='mirror')\n",
        "  feature_vector = np.concatenate((MFCC,MFCC_delta,MFCC_delta2))\n",
        "\n",
        "  return feature_vector"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj63YsQsl_ff"
      },
      "source": [
        "Generating CODEBOOK for every word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ltq5vkTRHvWm",
        "outputId": "288fe164-fda7-45e3-8702-60c65c05b5b1"
      },
      "source": [
        "classes = [\"down\",\"go\",\"left\",\"no\",\"off\",\"on\",\"right\",\"stop\",\"up\",\"yes\"]\n",
        "CB = [[] for i in range(10)]\n",
        "\n",
        "for i in range(10):\n",
        "  paths = glob.glob(\"/content/Dataset/Commands Dataset/train/\"+classes[i]+\"/*.wav\")\n",
        "  for audio_path in paths:\n",
        "    x, Fs = librosa.load(audio_path, sr=None)\n",
        "    window_dur = 0.03\n",
        "    frame_length = int(Fs*window_dur)\n",
        "    hop_length = int(Fs*window_dur/2)\n",
        "    thresh = 0.01\n",
        "\n",
        "    audio = endPointing(x, Fs, thresh, frame_length, hop_length)\n",
        "    dur = audio.shape[0]/Fs\n",
        "    if(dur >= 0.3):\n",
        "      feature_vector = featureExtraction(audio, Fs, frame_length, hop_length)\n",
        "    \n",
        "      for j in range(feature_vector.shape[1]):\n",
        "        CB[i].append(feature_vector[:,j])\n",
        "\n",
        "  print(classes[i]+\": \",len(CB[i]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "down:  86598\n",
            "go:  66492\n",
            "left:  64687\n",
            "no:  78917\n",
            "off:  42450\n",
            "on:  78762\n",
            "right:  69348\n",
            "stop:  64751\n",
            "up:  37352\n",
            "yes:  75912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mVOSgGHmGrn"
      },
      "source": [
        "Storing the codebook \\\\\n",
        "Note that generation of codebooks takes quite some time. \\\\\n",
        "Hence we prefer to store it once and instead of generating it everytime, we just load it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsJDsg9VYwsl"
      },
      "source": [
        "with open(\"CodeBook.txt\", \"wb\") as fp:\n",
        "  pickle.dump(CB, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_0egPtymhwQ"
      },
      "source": [
        "Loading the Codebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiWnXqt0mZ73"
      },
      "source": [
        "with open(\"CodeBook.txt\", \"rb\") as fp:\n",
        "  CB = pickle.load(fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZFr215Amvgv"
      },
      "source": [
        "Definition of Functions for \n",
        "\n",
        "1.   Vector Quantization\n",
        "2.   Calculating Minimum Distortion w.r.t a codebook\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDhJcPInf19_"
      },
      "source": [
        "def VQ_CB(CB, k):\n",
        "  VQ = np.array(CB)\n",
        "  Kmeans, distortion = kmeans(VQ, k_or_guess=k)\n",
        "\n",
        "  return Kmeans\n",
        "\n",
        "def min_Distortion(test_vec, Kmeans):\n",
        "  dist = Kmeans - test_vec\n",
        "  dist = np.square(dist)\n",
        "  dist = np.sqrt(np.sum(dist, axis=1))\n",
        "  min_dist = np.min(dist)\n",
        "\n",
        "  return min_dist"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDRYsgVUnP3I"
      },
      "source": [
        "Performing Vector Quantization to obtain 64 K-means representative vectors for every codebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7i2UWiWoYsI"
      },
      "source": [
        "Kmeans = []\n",
        "\n",
        "for i in range(10):\n",
        "  Kmeans.append(VQ_CB(CB[i], 64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmURlLdenbZw"
      },
      "source": [
        "Storing the Kmeans list of vectors. \\\\\n",
        "Please note that this algorithm also takes quite some time. \\\\\n",
        "Hence, we generate them once and then next time onwards we just load it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgZcJQwDnpgR"
      },
      "source": [
        "with open(\"kmeans.txt\", \"wb\") as fp:\n",
        "  pickle.dump(Kmeans, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87kmVZHgnw1y"
      },
      "source": [
        "Loading the Kmeans list of vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG4X8mxyN37J"
      },
      "source": [
        "#Don't run the above code. Directly load the Kmeans file that I have attached with the code named as \"kmeans.txt\". Because running kmeans algorithm will take a lot of time.\n",
        "\n",
        "with open(\"kmeans.txt\", \"rb\") as fp:\n",
        "  Kmeans = pickle.load(fp)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNk8P5Men5Bi"
      },
      "source": [
        "TASK A \\\\\n",
        "Performing Prediction on Clean Test utterances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBiWLW53D5RY",
        "outputId": "ba54c70a-b187-4ac4-e765-a80c06599f8d"
      },
      "source": [
        "correct = 0\n",
        "count = 0\n",
        "confusion_matrix = np.zeros((10,10))\n",
        "min_index = 0\n",
        "\n",
        "for i in range(10):\n",
        "  paths = glob.glob(\"/content/Dataset/Commands Dataset/test_clean/\"+classes[i]+\"/*.wav\")\n",
        "  for audio_path in paths:\n",
        "\n",
        "    x, Fs = librosa.load(audio_path, sr=None)\n",
        "    window_dur = 0.03\n",
        "    frame_length = int(Fs*window_dur)\n",
        "    hop_length = int(Fs*window_dur/2)\n",
        "    thresh = 0.01\n",
        "\n",
        "    audio = endPointing(x, Fs, thresh, frame_length, hop_length)\n",
        "    dur = audio.shape[0]/Fs\n",
        "    Prediction = \"down\"\n",
        "    min_tot_dist = 99999999999\n",
        "    if(dur >= 0.3):\n",
        "      count = count+1\n",
        "      feature_vector = featureExtraction(audio, Fs, frame_length, hop_length)\n",
        "      \n",
        "      for k in range(10):\n",
        "        total_dist = 0\n",
        "        for j in range(feature_vector.shape[1]):\n",
        "          min_dist = min_Distortion(feature_vector[:,j],Kmeans[k])\n",
        "          total_dist = total_dist + min_dist\n",
        "        \n",
        "        if(total_dist < min_tot_dist):\n",
        "          min_tot_dist = total_dist\n",
        "          Prediction = classes[k]\n",
        "          min_index = k\n",
        "\n",
        "      confusion_matrix[i,min_index] = confusion_matrix[i,min_index]+1\n",
        "      if(Prediction == classes[i]):\n",
        "        correct = correct+1\n",
        "  confusion_matrix[i] = confusion_matrix[i]/np.sum(confusion_matrix[i])\n",
        "  print(classes[i]+\" testing complete, accuracy so far:\", correct/count) \n",
        "\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "down testing complete, accuracy so far: 0.7107438016528925\n",
            "go testing complete, accuracy so far: 0.6621923937360179\n",
            "left testing complete, accuracy so far: 0.6761904761904762\n",
            "no testing complete, accuracy so far: 0.6771929824561403\n",
            "off testing complete, accuracy so far: 0.6790123456790124\n",
            "on testing complete, accuracy so far: 0.6942355889724311\n",
            "right testing complete, accuracy so far: 0.7132667617689016\n",
            "stop testing complete, accuracy so far: 0.7284183994959043\n",
            "up testing complete, accuracy so far: 0.7265717674970344\n",
            "yes testing complete, accuracy so far: 0.7409766454352441\n",
            "[[0.7107438  0.04545455 0.02479339 0.10743802 0.01652893 0.04545455\n",
            "  0.00826446 0.00826446 0.01652893 0.01652893]\n",
            " [0.05365854 0.60487805 0.02439024 0.13658537 0.02439024 0.01463415\n",
            "  0.01463415 0.0097561  0.10731707 0.0097561 ]\n",
            " [0.04918033 0.01639344 0.71038251 0.04371585 0.01092896 0.01639344\n",
            "  0.0273224  0.01092896 0.04371585 0.07103825]\n",
            " [0.12       0.11555556 0.02666667 0.68       0.00444444 0.01333333\n",
            "  0.00444444 0.00444444 0.03111111 0.        ]\n",
            " [0.02564103 0.00854701 0.02564103 0.         0.69230769 0.13675214\n",
            "  0.00854701 0.02564103 0.07692308 0.        ]\n",
            " [0.04888889 0.01777778 0.00444444 0.01333333 0.08       0.76\n",
            "  0.01777778 0.         0.05777778 0.        ]\n",
            " [0.02439024 0.02439024 0.03902439 0.01463415 0.0195122  0.01463415\n",
            "  0.82439024 0.         0.03902439 0.        ]\n",
            " [0.03243243 0.         0.02702703 0.00540541 0.01081081 0.01081081\n",
            "  0.00540541 0.84324324 0.06486486 0.        ]\n",
            " [0.04040404 0.01010101 0.09090909 0.02020202 0.05050505 0.04040404\n",
            "  0.02020202 0.03030303 0.6969697  0.        ]\n",
            " [0.01010101 0.         0.01515152 0.02525253 0.02020202 0.00505051\n",
            "  0.04040404 0.01010101 0.01010101 0.86363636]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t42e2QwHoMLi"
      },
      "source": [
        "TASK B \\\\\n",
        "Performing Prediction on Noisy Test utterances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FL5tw6HoISC",
        "outputId": "007ddd0d-b31d-4250-ebd9-11edc493c3ef"
      },
      "source": [
        "correct = 0\n",
        "count = 0\n",
        "confusion_matrix = np.zeros((10,10))\n",
        "min_index = 0\n",
        "\n",
        "for i in range(10):\n",
        "  paths = glob.glob(\"/content/Dataset/Commands Dataset/test_noisy/\"+classes[i]+\"/*.wav\")\n",
        "  for audio_path in paths:\n",
        "\n",
        "    x, Fs = librosa.load(audio_path, sr=None)\n",
        "    window_dur = 0.03\n",
        "    frame_length = int(Fs*window_dur)\n",
        "    hop_length = int(Fs*window_dur/2)\n",
        "    thresh = 0.1\n",
        "\n",
        "    audio = endPointing(x, Fs, thresh, frame_length, hop_length)\n",
        "    dur = audio.shape[0]/Fs\n",
        "    Prediction = \"down\"\n",
        "    min_tot_dist = 99999999999\n",
        "    if(dur >= 0.3):\n",
        "      count = count+1\n",
        "      feature_vector = featureExtraction(audio, Fs, frame_length, hop_length)\n",
        "      \n",
        "      for k in range(10):\n",
        "        total_dist = 0\n",
        "        for j in range(feature_vector.shape[1]):\n",
        "          min_dist = min_Distortion(feature_vector[:,j],Kmeans[k])\n",
        "          total_dist = total_dist + min_dist\n",
        "        \n",
        "        if(total_dist < min_tot_dist):\n",
        "          min_tot_dist = total_dist\n",
        "          Prediction = classes[k]\n",
        "          min_index = k\n",
        "\n",
        "      confusion_matrix[i,min_index] = confusion_matrix[i,min_index]+1\n",
        "      if(Prediction == classes[i]):\n",
        "        correct = correct+1\n",
        "  confusion_matrix[i] = confusion_matrix[i]/np.sum(confusion_matrix[i])\n",
        "  print(classes[i]+\" testing complete, accuracy so far:\", correct/count)\n",
        "print(confusion_matrix)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "down testing complete, accuracy so far: 0.34415584415584416\n",
            "go testing complete, accuracy so far: 0.3652173913043478\n",
            "left testing complete, accuracy so far: 0.39862542955326463\n",
            "no testing complete, accuracy so far: 0.4056603773584906\n",
            "off testing complete, accuracy so far: 0.42391304347826086\n",
            "on testing complete, accuracy so far: 0.40931780366056575\n",
            "right testing complete, accuracy so far: 0.4149560117302053\n",
            "stop testing complete, accuracy so far: 0.4243641231593039\n",
            "up testing complete, accuracy so far: 0.42213642213642216\n",
            "yes testing complete, accuracy so far: 0.441073512252042\n",
            "[[0.34415584 0.03246753 0.15584416 0.03896104 0.2987013  0.03896104\n",
            "  0.00649351 0.         0.01948052 0.06493506]\n",
            " [0.01315789 0.40789474 0.11842105 0.03947368 0.25       0.02631579\n",
            "  0.01315789 0.01315789 0.09210526 0.02631579]\n",
            " [0.04918033 0.03278689 0.52459016 0.03278689 0.21311475 0.\n",
            "  0.01639344 0.01639344 0.04918033 0.06557377]\n",
            " [0.05263158 0.10526316 0.09022556 0.42105263 0.2406015  0.0075188\n",
            "  0.0075188  0.0075188  0.03759398 0.03007519]\n",
            " [0.         0.02777778 0.05555556 0.02777778 0.63888889 0.08333333\n",
            "  0.         0.02777778 0.11111111 0.02777778]\n",
            " [0.06382979 0.02836879 0.02836879 0.02836879 0.38297872 0.36170213\n",
            "  0.0212766  0.         0.08510638 0.        ]\n",
            " [0.03703704 0.04938272 0.14814815 0.02469136 0.17283951 0.01234568\n",
            "  0.45679012 0.03703704 0.04938272 0.01234568]\n",
            " [0.         0.01538462 0.09230769 0.         0.24615385 0.\n",
            "  0.         0.52307692 0.06153846 0.06153846]\n",
            " [0.06666667 0.06666667 0.2        0.03333333 0.23333333 0.\n",
            "  0.         0.03333333 0.36666667 0.        ]\n",
            " [0.0125     0.         0.1        0.025      0.125      0.\n",
            "  0.05       0.0375     0.025      0.625     ]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}